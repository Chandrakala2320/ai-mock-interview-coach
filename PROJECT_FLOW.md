## Project Flow

Chat Trigger → AI Agent → Local LLM (Ollama) → Response

The system starts when the user sends a message.
The AI Agent behaves like a professional interviewer by asking role-based questions.
User responses are evaluated and scored.
Constructive feedback and improvement tips are provided.

The AI model runs locally using Ollama to avoid API costs.
